{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly,  I load in the libraries I will need the below codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reading  Train Datas in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fruit 360 dataset contains pre defined training and test splits, divided into two folders. Instead of using these, I am going to read in fruit images from the training folders, and create my own train/test splits later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datas = list()\n",
    "training_labels = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirPath in glob.glob(\"fruits/fruits-360/Training/*\"):\n",
    "    imageLabel = dirPath.split('/')[-1]\n",
    "    for imagePath in glob.glob(os.path.join(dirPath, '*')):\n",
    "        image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (32, 32))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        training_datas.append(image)\n",
    "        training_labels.append(imageLabel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60486, 60486)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_datas), len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datas = np.array(training_datas)\n",
    "training_labels = np.array(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60486, 32, 32, 3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_datas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {key : value for key, value in enumerate(np.unique(training_labels))}\n",
    "label_to_id = {key:value for value, key in id_to_label.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = np.array([label_to_id[item] for item in training_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape = (60486, 32, 32, 3), training labels shape =  (60486,)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data shape = {1}, training labels shape =  {0}\".format(training_labels.shape, training_datas.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = list(id_to_label.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reading Validation Datas in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datas = list()\n",
    "validation_labels = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirPath in glob.glob(\"fruits/fruits-360/Test/*\"):\n",
    "    imageLabel = dirPath.split('/')[-1]\n",
    "    for imagePath in glob.glob(os.path.join(dirPath, '*')):\n",
    "        image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (32, 32))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        validation_datas.append(image)\n",
    "        validation_labels.append(imageLabel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20618, 20618)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_datas), len(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datas = np.array(validation_datas)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = np.array([label_to_id[item] for item in validation_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data shape = (20618, 32, 32, 3), validation labels shape =  (20618,)\n"
     ]
    }
   ],
   "source": [
    "print(\"validation data shape = {1}, validation labels shape =  {0}\".format(validation_labels.shape, validation_datas.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preparing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_x_n, training_set_y_n = training_datas,  training_labels\n",
    "validation_set_x_n, validation_set_y_n = validation_datas,  validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of the images pixels.\n",
    "training_set_x_n = training_set_x_n / 255\n",
    "validation_set_x_n = validation_set_x_n / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_training_set_x_n = training_set_x_n.reshape(training_set_x_n.shape[0], 32*32*3)\n",
    "flat_validation_set_x_n = validation_set_x_n.reshape(validation_set_x_n.shape[0], 32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(training_set_y_n).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([115, 115, 115, ...,  77,  77,  77])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set_y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#One Hot Encode the Output\n",
    "training_set_y_n = keras.utils.to_categorical(training_set_y_n)\n",
    "validation_set_y_n = keras.utils.to_categorical(validation_set_y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60486, 120)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_y_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sizes: (60486, 32, 32, 3) (20618, 32, 32, 3) (60486, 120) (20618, 120)\n",
      "Flattened: (60486, 3072) (60486, 3072)\n"
     ]
    }
   ],
   "source": [
    "print('Original Sizes:', training_set_x_n.shape, validation_set_x_n.shape, training_set_y_n.shape, validation_set_y_n.shape)\n",
    "print('Flattened:', flat_training_set_x_n.shape, flat_training_set_x_n.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TRAINING ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,Activation,BatchNormalization\n",
    "from keras.optimizers import Adamax\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fruit Classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 120)               0         \n",
      "=================================================================\n",
      "Total params: 130,040\n",
      "Trainable params: 129,752\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name = 'Fruit Classification')\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(32,32,3),padding='same'))\n",
    "model.add(LeakyReLU(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(LeakyReLU(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same'))\n",
    "model.add(LeakyReLU(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same'))\n",
    "model.add(LeakyReLU(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "#model.add(LeakyReLU(0.1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60486 samples, validate on 20618 samples\n",
      "Epoch 1/10\n",
      "60486/60486 [==============================] - 68s 1ms/step - loss: 1.2607 - accuracy: 0.6674 - val_loss: 3.5854 - val_accuracy: 0.2343\n",
      "Epoch 2/10\n",
      "60486/60486 [==============================] - 70s 1ms/step - loss: 0.2206 - accuracy: 0.9385 - val_loss: 0.1524 - val_accuracy: 0.9579\n",
      "Epoch 3/10\n",
      "60486/60486 [==============================] - 71s 1ms/step - loss: 0.0995 - accuracy: 0.9721 - val_loss: 0.1312 - val_accuracy: 0.9575\n",
      "Epoch 4/10\n",
      "60486/60486 [==============================] - 68s 1ms/step - loss: 0.0597 - accuracy: 0.9835 - val_loss: 0.1066 - val_accuracy: 0.9687\n",
      "Epoch 5/10\n",
      "60486/60486 [==============================] - 65s 1ms/step - loss: 0.0378 - accuracy: 0.9904 - val_loss: 0.0614 - val_accuracy: 0.9824\n",
      "Epoch 6/10\n",
      "60486/60486 [==============================] - 67s 1ms/step - loss: 0.0280 - accuracy: 0.9929 - val_loss: 0.0605 - val_accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "60486/60486 [==============================] - 69s 1ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.0478 - val_accuracy: 0.9851\n",
      "Epoch 8/10\n",
      "60486/60486 [==============================] - 76s 1ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.0754 - val_accuracy: 0.9809\n",
      "Epoch 9/10\n",
      "60486/60486 [==============================] - 64s 1ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
      "Epoch 10/10\n",
      "60486/60486 [==============================] - 69s 1ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0696 - val_accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xc1959c590>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = Adamax(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_set_x_n,\n",
    "          training_set_y_n,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data = (validation_set_x_n, validation_set_y_n)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
